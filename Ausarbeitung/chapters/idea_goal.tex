% !TeX spellcheck = de_DE

\section{Idee und Zielsetzung} \label{idea_goal}

Der Grundlegende Gedanke zur Durchführung dieser Arbeit ist, den Bereich des Parallel Computings auf die Signalverarbeitung anzuwenden. In der Anwendung werden speziell Audiodateien im WAV-Dateiformat dazu herangezogen. In diesen WAV-Dateien sind Audiosignale für jeden Audiokanal gespeichert, was bei einer Erhöhung der Audiokanäle dazu führt, dass die Anzahl der gespeicherten Daten in Relation zu diesen vervielfacht wird. Die Wiedergabe dieser Audiodateien wird sehr wahrscheinlich wenig problematisch sein und auch bleiben. Diese Arbeit setzt jedoch bei der Analyse solcher Dateien an. Die Extraktion der anteiligen Tonfrequenzen ist in der Signalverarbeitung \underline{das} zentrale Werkzeug zur weiteren Verarbeitung von Audiodateien. Dieses Verfahren wird durch die Fourieranalyse bzw. Fouriertransformation realisiert und in Kapitel \ref{chap:signalprocessing} näher thematisiert. Im Grunde kann damit über komplexe mathematische Strukturen errechnet werden, aus welchen harmonischen Signalen mit unterschiedlicher Amplitude, Frequenz und Phase ein periodisches Signal zusammengesetzt ist. Das Ziel ist es, diese mathematischen Berechnungen auf die Shader-Kerne der Grafikkarte zu verteilen und parallel auszuführen, um damit eine Leistungssteigerung bzw. Performance-Steigerung zu erreichen. Herkömmliche  CPUs reichen technologiebedingt oft nicht mehr aus, um viele kleine Problemstellungen effizient und vor allem parallel zu berechnen. Die Parallelisierbarkeit ist auf die Anzahl der Threads einer CPU begrenzt. Im Beispiel des Anwendungsfalles wird ein Intel I7 7700k verwendet. Die technischen Spezifikationen geben vier Kerne an, wobei durch Hyperthreading Technologie acht logische Kerne realisiert werden. Somit können bis zu acht Rechenoperationen parallel ausgeführt werden. Diese Tatsache wird als Problemstellung angenommen und an dieser Stelle wird das Ziel definiert, dass statt wenig große Rechenoperationen im Bezug auf die Signalverarbeitung die nötigen Berechnungen auf viele kleinere Teilproblemstellungen herunter gebrochen werden, um diese mithilfe der Grafikkarte zu parallelisieren. Die Grafikkarte bietet durch frei programmierbare Shader-Kerne über Schnittstellen wie CUDA (Nvidia) oder OpenCL(AMD) die Möglichkeit, solche Aufgaben effizient zu lösen. Tausende solcher Kerne mit geteiltem Speicher (RAM) sind netzförmig auf einer GPU verbaut. Auf fundamentaler Ebene dienen sie dem Zweck, grafische Informationen in Form von Pixelinformationen oder Polygonen zu manipulieren bzw. auszuwerten. Somit ist die Hauptaufgabe einer Grafikkarte das Lösen von unzähligen Gleichungssystemen und anderen mathematischen Operationen. Die ALUs (Arithmetic Logic Unit) übernehmen somit den fundamentalen Baustein einer Grafikkarte. 

Eine naheliegende \enquote{Zweckentfremdung} der Shader-Kerne ist die Ausführung von individuellem Code basierend auf der Lösung von rechenintensiven Problemen, die sich auf viele kleine Teilprobleme zerlegen lassen. Im Anwendungsfall der Audiosignalverarbeitung ist eine solche Situation gegeben. Das Grundproblem besteht darin, aus den Audiodaten einer WAV-Datei mithilfe der Verwendung von Fourier Transformationen die anteiligen Tonfrequenzen zu berechnen und digital darzustellen. Die Aufteilung des zu untersuchenden Bereichs einer Tonspur auf die CUDA-Kerne wird von der CPU bzw. dem Host-System durchgeführt. Jedem Kern wird von diesem Bereich eine Menge an Audiosamples zugeordnet und über die Fouriertransformation die Stärke des Auftretens der zugeteilten Frequenz berechnet. Durch die Zusammenarbeit von CPU und Shader-Kernen der Grafikkarte entsteht somit ein heterogenes System zur Lösung der o.g. Problemstellung. 
Die errechneten anteiligen Frequenzen werden letztlich mithilfe einer TCP-Schnittstelle über einen Webserver zur Laufzeit visualisiert. Grundsätzlich thematisiert diese Arbeit ausschließlich das WAV-Format. Die Architektur des zugrundeliegenden Programms ist jedoch leicht auf andere Formate übertragbar.


Ein weiterer Teilbereich dieser Arbeit umfasst die Manipulation einer Audioquelle über die CUDA-Schnittstelle.
Das Ziel ist es, einen variablen räumlichen Punkt zu wählen der als Quelle eines Audiosignals dient, um dann diese mithilfe der Shader-Kerne zu manipulieren, sodass über Nutzereingaben, die die relative Position zur Audioquelle verändern, ein positionsbezogener Effekt entsteht. Genauer werden Signalabschwächung und die räumliche \enquote{Lage} des Signals mithilfe einer Matrix bzw. eines Koordinatensystems (CUDA-Grid) in Abhängigkeit der Position verrechnet bzw. manipuliert. Dadurch entstehen Übergangszustände von Daten, die wiederum die Eingabedaten für darauffolgende Iterationen darstellen.
Die Quelle des Signals ist zur Laufzeit variabel, kann also durch bestimmte Eingaben verändert bzw. verschoben werden.
Einzelheiten zu diesen Teilbereichen der Zielsetzung wird in den jeweiligen Kapiteln näher beschrieben.