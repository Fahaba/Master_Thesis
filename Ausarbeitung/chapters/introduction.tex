% !TeX spellcheck = de_DE

\section{Einleitung}

In einer digitalen Welt des immer größer währenden Realismus in künstlichen Umgebungen müssen aufgrund hoher Komplexität und der reinen Masse an Daten, werden bereits Teilbereiche der Bildentwicklung über die Fähigkeit für hohe Parallelisierung von Grafikkarten realisiert. Beispielsweise ist die Technik des Raytracings und der damit verbundenen Fähigkeit realistische Schatten und Licht in künstlichen Umgebungen wie in der Bildverarbeitung, der Gaming-Szene oder VR-Anwendungen heutzutage schon sehr weit erforscht. Die Echtheit von 3D-Anwendungen hat einen immer höheren Stellenwert für deren Benutzer. Gleichzeitig sticht jedoch heraus, dass die Entwickler solcher Anwendungen im Bereich von Audiorealismus eigene Schnittstellen realisieren, die z.B. Positionsbezogene Audiowiedergabe zu simulieren versuchen. Im Bereich der Spielentwicklung gibt es sogar bei Triple-A Titeln viele Beispiele, deren positionsbezogene Audioschnittstellen nicht sehr weit Entwickelt sind. Auch in der Audioforschung wären solche Schnittstellen in vielen Bereichen wie Auditorische Szenenanalyse, Binauraltechnik, Hörtechnik in der biomedizinischen Technik, Lärmforschung und Psychoakustik \cite{rwth_survey_categories} brauchbar. Aus einem Bericht von TECHPOWERUP \cite{atricle_audiotracing} vom 16.08.2018 ist zu entnehmen, dass Nvidia in der RTX-Reihe von Grafikkarten eine solche Schnittstelle für positionsbezogenes Audio etablieren wollen, indem angenommen wird, dass sich Soundquellen analog zu Lichtquellen auf unterschiedlichen Oberflächen verschieden Verhalten. Der Entwicklungsstand dieser Schnittstelle ist bis jetzt nicht bekannt.

Diese Abschlussarbeit beschäftigt sich mit dem Thema positionsbezogenem Audio und versucht eine initiale Herangehensweise zu liefern, mit der eine solche Schnittstelle in Zukunft realisiert werden könnte. Die Implementierung eines solch umfassenden Themenbereichs übersteigt den Umfang dieser Abschlussarbeit immens. Weitere zukünftige Forschungsarbeiten wären nötig, um dieses Thema weiter voranzutreiben. Die hier implementierten Techniken beschäftigen sich zum einen mit der parallelen Extraktion von Anteiligen harmonischen Frequenzen einer Audiodatei und deren Visualisierung. Zum anderen wird eine Möglichkeit geboten, eine laufende Wiedergabe eines hier genannten Audioparkours zu manipulieren und so eine positionsbezogene Simulation von Audio zu erhalten.