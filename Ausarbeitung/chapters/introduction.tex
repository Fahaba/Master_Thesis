% !TeX spellcheck = de_DE

\section{Einleitung}

In einer digitalen Welt des immer größer werdenden Realismus in künstlichen Umgebungen werden aufgrund hoher Komplexität und der reinen Masse an Daten bereits Teilbereiche der Bildentwicklung über die Fähigkeit für hohe Parallelisierung von Grafikkarten verwirklicht. Beispielsweise ist die Technik des Raytracings und die damit verbundene Fähigkeit, realistische Schatten und Licht in künstlichen Umgebungen zu erzeugen in der Bildverarbeitung, der Gaming-Szene oder VR-Anwendungen heutzutage schon sehr weit erforscht. Die Echtheit von 3D-Anwendungen hat einen immer höheren Stellenwert für deren Benutzer. Gleichzeitig sticht jedoch heraus, dass die Entwickler solcher Anwendungen im Bereich von Audiorealismus eigene Schnittstellen realisieren, die z.B. positionsbezogene Audiowiedergabe zu simulieren versuchen. Im Bereich der Spielentwicklung gibt es sogar bei Triple-A-Titeln viele Beispiele, deren positionsbezogene Audioschnittstellen nicht sehr weit entwickelt sind. Auch in der Audioforschung wären solche Schnittstellen in vielen Bereichen wie Auditorische Szenenanalyse, Binauraltechnik, Hörtechnik in der biomedizinischen Technik, Lärmforschung und Psychoakustik \cite{rwth_survey_categories} brauchbar. Aus einem Bericht von TECHPOWERUP \cite{atricle_audiotracing} vom 16.08.2018 ist zu entnehmen, dass der Grafikkarten-Hersteller Nvidia in der RTX-Reihe seiner Produkte eine solche Schnittstelle für positionsbezogenes Audio etablieren will, indem angenommen wird, dass sich Soundquellen analog zu Lichtquellen auf unterschiedlichen Oberflächen verschieden verhalten. Der Entwicklungsstand dieser Schnittstelle ist bis jetzt nicht bekannt.

Diese Abschlussarbeit beschäftigt sich mit dem Thema paralleler Signalverarbeitung in Form von paralleler Anwendung von Fouriertransformationen im ersten und positionsbezogenem Audio im zweiten Teilprojekt. Es wird versucht eine initiale Herangehensweise zu liefern, mit der solche Schnittstelle in Zukunft realisiert werden können. Die Implementierung eines solch umfassenden Themenbereichs übersteigt den Umfang dieser Abschlussarbeit immens. Weitere zukünftige Forschungsarbeiten wären nötig, um dieses Thema weiter voranzutreiben. Die hier implementierten Techniken beschäftigen sich zum einen mit der parallelen Extraktion von anteiligen harmonischen Frequenzen einer Audiodatei und deren Visualisierung über Fouriertransformationen. Zum anderen wird eine Möglichkeit geboten, eine laufende Wiedergabe eines hier sogenannten Audioparcours zu manipulieren, wodurch eine positionsbezogene Simulation von Audio erreicht wird.

Der Quellcode, auf dem diese Abschlussarbeit, liegt auf einem Github-Repository \cite{fahaba_github} unter folgendem Link:  \texttt{\href{https://github.com/fahaba/Master\_Thesis}{https://github.com/fahaba/Master\_Thesis}}.