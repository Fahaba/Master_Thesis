% !TeX spellcheck = de_DE

\section{Zusammenfassung}

In dieser Arbeit wurden zwei Projekte vorgestellt, wobei das erstere AudioTracer Projekt größere Entwicklungs- und Recherchearbeit erforderte. Dieses besteht aus mehreren Modulen, die eigene Zuständigkeitsbereiche abdecken. Analog zu Abbildung \ref{fig:OV} besteht dieses Teilprojekt aus den Modulen StreamWriter, jeweils einem CUDA Modul für C und Python und aus einem Bokeh Webserver Modul. Der StreamWriter liest eine WAV-Datei ein und macht die darauf gewonnenen Sampledaten für das C- oder Python- CUDA-Modul in Form eines TCP-Streams verfügbar. Das C CUDA-Modul empfängt diese Daten bis zu jeweils einem gewissen Threshhold, wandelt diese in eine komplexe Repräsentation und startet eine CUDA-Routine. Jedem CUDA-Kernel-Thread wird ein Teilbereich der Daten zugewiesen. Die genaue Aufteilung kann der Sektion \ref{sec:audiotracer} entnommen werden. Jeder CUDA-Thread wendet auf die zugewiesenen Teilbereiche eine Fouriertransformation an. Im Falle des C-Moduls wird eine diskrete Fouriertransformation verwendet. Die Ausgabe beschreibt, welche harmonischen Frequenzen wie stark in den übermittelten Audiodaten anteilig sind.

Das Python CUDA-Modul weist einen ähnlichen Aufbau zum C-Modul auf. Prägnant ist jedoch, dass der Quellcode im Vergleich durch weniger notwendige Umformungen und Typtreue - wahrscheinlich mit Performance Verlusten - wesentlich kleiner ausfällt. Ein Performance Vergleich wurde hier nicht vorgenommen. Das Python Modul benutzt eine Fast Fourier Transformation aus dem Paket \texttt{cupy} um die Frequenzen zu extrahieren.

Beide CUDA-Module kommunizieren das Ergebnis Array über eine weitere \\TCP-Schnittstelle mit dem Python Bokeh Server Modul. Dabei handelt es sich um einen Visualisierungswebserver, der mithilfe von AJAX POST-Requests Daten an den Browser weiterleiten kann, die durch vorgefertigte JavaScript-Anbindungen in eine SVG-Grafik visualisiert werden.

Der Ablauf von StreamWriter bis zur Visualisierung im Browser findet im Kontext zu Grafik \ref{fig:OV} von links nach rechts statt.

Das zweite Teilprojekt AudioParcours bietet eine Möglichkeit, eine WAV-Datei während der laufenden Wiedergabe über CUDA-Routinen zu manipulieren, um den Effekt einer positionsbezogenen Audiowiedergabe zu simulieren. Dieses Projekt wurde in Python implementiert. Python liefert die notwendigen Pakete \texttt{Sounddevice} und \texttt{PyCUDA}. Ersteres ermöglicht eine Implementierung eines Audiostreams, wobei immer eine bestimmte Anzahl an Audiosamples wiedergegeben werden, bis eine Callback-Funktion aufgerufen wird, mit der die Audiodaten des nächsten Blocks festgelegt werden können. Parallel dazu können Nutzereingaben getätigt werden, die bewirken, dass CUDA-Operationen vorgenommen werden, die die Signaldaten in Abhängigkeit der getätigten Nutzereingaben manipuliert. Diese daraus gewonnen Daten werden in der Callback-Methode zu gegebenem Zeitpunkt verwendet. 